{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if include sensor_id then can fit quite a good model - but this would be a model that would only be able to predict at those locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "# import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor \n",
    "# import xgboost as xgb\n",
    "from sklearn.pipeline import Pipeline\n",
    "# import folium\n",
    "# import branca.colormap as cm\n",
    "# from eli5.sklearn import PermutationImportance\n",
    "# import joblib\n",
    "# import os\n",
    "# import psutil\n",
    "# import geopy.distance\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "from Functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size_m = 500\n",
    "input_csv =\"../../Cleaned_data/FormattedDataForModelling/formatted_data_for_modelling_allsensors_{}.csv\".format(buffer_size_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run models with cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the error metrics for the cross-validation to return, and the parameters of the cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metrics = ['neg_mean_absolute_error', 'r2', 'neg_root_mean_squared_error', 'neg_mean_absolute_percentage_error']\n",
    "cv_parameters = KFold(n_splits=10, random_state=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model_pipeline = Pipeline(steps=[['scaler',StandardScaler()],['rf_regressor', RandomForestRegressor(random_state = 1, n_jobs = 10)]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare data for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull, Yfull, data_time_columns = prepare_x_y_data(input_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cut off data post-Covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull= Xfull[0:2643750]\n",
    "Yfull= Yfull[0:2643750]\n",
    "data_time_columns = data_time_columns[0:2643750] # end of 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add sensor ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensor_ids = pd.read_csv(input_csv)['sensor_id']\n",
    "sensor_ids= sensor_ids[0:2643750]\n",
    "Xfull['sensor_id'] = sensor_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose which month_num and weekday_num option to include"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using the dummy variables\n",
    "# Xfull.drop(['Cos_month_num', 'Sin_month_num', 'Cos_weekday_num', 'Sin_weekday_num'], axis=1)\n",
    "# If using the cyclical variables\n",
    "Xfull.drop(['Monday', 'Saturday', 'Sunday', 'Thursday', 'Tuesday', 'Wednesday',\n",
    "       'month_2', 'month_3', 'month_4', 'month_5', 'month_6', 'month_7',\n",
    "       'month_8', 'month_9', 'month_10', 'month_11', 'month_12'], axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del Xfull['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove spatial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatial_cols = ['betweenness', 'lights',  'memorials', 'trees','bus-stops', 'tram-stops', 'metro-stations', \n",
    "            'taxi-ranks', 'big-car-parks', 'street_inf_Bicycle Rails', 'street_inf_Bollard','street_inf_Drinking Fountain',\n",
    "            'street_inf_Floral Crate/Planter Box','street_inf_Horse Trough', 'street_inf_Information Pillar',\n",
    "            'street_inf_Litter Bin', 'street_inf_Seat', 'street_inf_Tree Guard','landmarks_Community Use', \n",
    "            'landmarks_Mixed Use','landmarks_Place Of Assembly', 'landmarks_Place of Worship', 'landmarks_Retail', \n",
    "            'landmarks_Transport', 'landmarks_Education Centre','landmarks_Leisure/Recreation', 'landmarks_Office',\n",
    "       'street_inf_Barbeque', 'street_inf_Hoop', 'street_inf_Picnic Setting', 'landmarks_Specialist Residential Accommodation',\n",
    "       'landmarks_Vacant Land', 'landmarks_Purpose Built','landmarks_Health Services', 'avg_n_floors', 'buildings_Community Use',\n",
    "       'buildings_Education', 'buildings_Entertainment', 'buildings_Events','buildings_Hospital/Clinic', 'buildings_Office', 'buildings_Parking',\n",
    "       'buildings_Public Display Area', 'buildings_Residential','buildings_Retail', 'buildings_Storage', 'buildings_Unoccupied',\n",
    "       'buildings_Working', 'buildings_Transport']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_save = Xfull[spatial_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xfull.drop(spatial_cols, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the sensor ID\n",
    "Xfull_sensorid = Xfull.loc[:, Xfull.columns != 'distance_from_centre']\n",
    "# Keep only the distance from the centre\n",
    "Xfull_distance_from_centre = Xfull.loc[:, Xfull.columns != 'sensor_id']\n",
    "# Keep no spatial variables\n",
    "Xfull_nospatialvariables = Xfull.loc[:, ~Xfull.columns.isin(['sensor_id', 'distance_from_centre'])]\n",
    "# Version with spatial variables\n",
    "Xfull = pd.concat([Xfull_distance_from_centre, columns_to_save], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original\n",
      "Ran in 163 minutes\n",
      "No Spatial Features\n"
     ]
    }
   ],
   "source": [
    "# Dataframe to store the scores for all the models\n",
    "error_metric_scores = pd.DataFrame()\n",
    "\n",
    "Xfulls = [Xfull,Xfull_nospatialvariables, Xfull_sensorid, Xfull_distance_from_centre]\n",
    "version = ['Original','No Spatial Features', 'Sensor ID', 'Distance From Centre']\n",
    "for num in range(0,len(Xfulls)):\n",
    "    # Get the right Xfull from list\n",
    "    Xfull=Xfulls[num]\n",
    "    print(version[num])\n",
    "    # Use cross_validate to return the error scores associated with this model and this data\n",
    "    start = time()\n",
    "    model_output = cross_validate(rf_model_pipeline, Xfull, Yfull, cv=cv_parameters, scoring=error_metrics, error_score=\"raise\")\n",
    "    end = time()\n",
    "    print('Ran in {} minutes'.format(round((end - start)/60),2))\n",
    "\n",
    "    # Formulate the different error scores into a dataframe\n",
    "    error_metrics_df =pd.DataFrame({'mae': round(abs(model_output['test_neg_mean_absolute_error'].mean()),2), \n",
    "                  'mape': round(abs(model_output['test_neg_mean_absolute_percentage_error'].mean()),2),\n",
    "                  'r2': round(abs(model_output['test_r2'].mean()),2), \n",
    "                  'rmse': round(abs(model_output['test_neg_root_mean_squared_error'].mean()),2)},\n",
    "                 index =[version[num]])\n",
    "\n",
    "    # Add evaluation metric scores for this model to the dataframe containing the metrics for each model\n",
    "    error_metric_scores = error_metric_scores.append(error_metrics_df)\n",
    "\n",
    "    # Save error scores for this distance to file\n",
    "#error_metrics_df.to_csv('Results/CV/ComparingModels/{}_{}m_error_metric_scores.csv'.format(model_name,buffer_size_m),index=False)    \n",
    "\n",
    "# Save dataframes of error metrics for each buffer distance \n",
    "error_metric_scores.to_csv('Results/CV/ComparingSpatialFeatures/comparingmodels_error_metric_scores.csv')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_metric_scores"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
